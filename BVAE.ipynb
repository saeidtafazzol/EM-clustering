{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObJDxk47vLu0u9IRgDJqfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaeedTafazzol/EM-clustering/blob/master/BVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEK_zoODwiyr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.distributions import *\n",
        "\n",
        "\n",
        "dataset1 = datasets.MNIST('../data', train=True,transform=transforms.ToTensor(), download=True)\n",
        "dataset2 = datasets.MNIST('../data', train=False,transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2,batch_size=64, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "p = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
        "q = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
        "print(kl_divergence(p,q))\n",
        "torch.eye(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiakS_CU5mpl",
        "outputId": "2b05d104-267e-40ce-b09e-8e92de725e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = torch.distributions.MultivariateNormal(torch.zeros((2,3,)),torch.stack((torch.eye(3),(torch.eye(3)))))\n",
        "q = torch.distributions.MultivariateNormal(torch.ones((2,3,)), torch.stack((torch.eye(3),(torch.eye(3)))))\n",
        "\n",
        "kl_divergence(p,q)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XnB9ti49rVM",
        "outputId": "5080c2a8-47bb-4014-ddef-3a209b900b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5000, 1.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.tensor(False),dtype=float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzYV5_ydi1lj",
        "outputId": "67a0f605-23f1-44e4-d39c-aea10b36e457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,z=10):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(28*28,256)\n",
        "    self.l2 = nn.Linear(256,128)    \n",
        "    self.l3 = nn.Linear(128,128)\n",
        "    self.l4 = nn.Linear(128,64)\n",
        "    self.mean = nn.Linear(64 ,10)\n",
        "    self.log_std = nn.Linear(64 ,10)\n",
        "\n",
        "  def forward(self, img):\n",
        "    img = img.reshape(-1,28*28)\n",
        "    out = F.leaky_relu(self.l1(img))\n",
        "    out = F.leaky_relu(self.l2(out))\n",
        "    out = F.leaky_relu(self.l3(out))\n",
        "    out = F.leaky_relu(self.l4(out))\n",
        "    mean = \tF.tanh(self.mean(out))\n",
        "    log_std = self.log_std(out)\n",
        "    return mean,log_std\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(10,64)\n",
        "    self.l2 = nn.Linear(64,128)\n",
        "    self.l3 = nn.Linear(128,128)\n",
        "    self.l4 = nn.Linear(128,256)\n",
        "    self.ber = nn.Linear(256 ,28*28)\n",
        "  def forward(self, lat):\n",
        "    out = F.leaky_relu(self.l1(lat))\n",
        "    out = F.leaky_relu(self.l2(out))\n",
        "    out = F.leaky_relu(self.l3(out))\n",
        "    out = F.leaky_relu(self.l4(out))\n",
        "    return\tF.sigmoid(self.ber(out))\n"
      ],
      "metadata": {
        "id": "tOr444Ycw4DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class autoencoder(object):\n",
        "  def __init__(self):\n",
        "    self.decoder = Decoder().to(device)\n",
        "    self.encoder = Encoder().to(device)\n",
        "    self.optimizer =  torch.optim.Adam(list(self.encoder.parameters())+list(self.decoder.parameters()),lr=1e-3)\n",
        "\n",
        "\n",
        "\n",
        "  def train(self,data_loader):\n",
        "    img, label = next(iter(data_loader))\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    beta = 5\n",
        "\n",
        "    mean,log_std = self.encoder(img)\n",
        "    # print(var.shape)\n",
        "    # var = torch.full((var.shape[1],), var)\n",
        "    # cov_mat = torch.diag(var,dim=-1)#.unsqueeze(dim=0)\n",
        "    # print(cov_mat)\n",
        "    # print(cov_mat.shape)\n",
        "\n",
        "    var = torch.exp(2*log_std)\n",
        " \n",
        "    a = torch.arange(0,var.shape[1]).to(device)\n",
        "    cov_mat = torch.zeros((var.shape[0],var.shape[1],var.shape[1])).to(device)\n",
        "    cov_mat[:,a,a] = var\n",
        "\n",
        "    nor_dist = torch.distributions.MultivariateNormal(mean, cov_mat)\n",
        "\n",
        "    standard_nor = torch.distributions.MultivariateNormal(torch.zeros(mean.shape[1]), torch.eye(cov_mat.shape[1]))\n",
        "\n",
        "    latent = standard_nor.sample((mean.shape[0],))*torch.exp(log_std) + mean\n",
        "\n",
        "    bern = self.decoder(latent)\n",
        "    \n",
        "    # ber_dist = Bernoulli(bern)\n",
        "    \n",
        "    # generated = ber_dist.sample().reshape(-1,1,28,28)\n",
        "    \n",
        "    # bin_img = (img.reshape(-1,28*28)>0.5).float()\n",
        "    # print(ber_dist.log_prob(bin_img).shape)\n",
        "    # loss =  -ber_dist.log_prob(bin_img).sum(1).mean() + beta*kl_divergence(nor_dist,standard_nor).mean(0)#nn.MSELoss()(img,generated)#nn.CrossEntropyLoss()(labeled,label) +\n",
        "    # print(nn.BCELoss()(bern,img.reshape(-1,28*28)).shape)\n",
        "    loss =  nn.BCELoss(reduction='sum')(bern,img.reshape(-1,28*28))/torch.tensor(64) + beta*kl_divergence(nor_dist,standard_nor).mean(0)\n",
        "    self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    # torch.nn.utils.clip_grad_norm_(self.encoder.parameters(), 10)\n",
        "    # torch.nn.utils.clip_grad_norm_(self.decoder.parameters(), 10)\n",
        "\n",
        "    self.optimizer.step()\n",
        "    \n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "3wdeQSDv0-Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto = autoencoder()\n",
        "loss = 0\n",
        "\n",
        "for i in range(1001):\n",
        "  loss+= auto.train(train_loader)\n",
        "  if (i+1)%100==0:\n",
        "    print(i,loss/100)\n",
        "    loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7uDaq2t4Ldn",
        "outputId": "197ce6db-11d4-4a15-dd25-6a11b2e9e9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 tensor(249.2283, grad_fn=<DivBackward0>)\n",
            "199 tensor(205.8818, grad_fn=<DivBackward0>)\n",
            "299 tensor(203.9852, grad_fn=<DivBackward0>)\n",
            "399 tensor(201.1816, grad_fn=<DivBackward0>)\n",
            "499 tensor(199.2083, grad_fn=<DivBackward0>)\n",
            "599 tensor(198.9433, grad_fn=<DivBackward0>)\n",
            "699 tensor(198.0245, grad_fn=<DivBackward0>)\n",
            "799 tensor(195.5209, grad_fn=<DivBackward0>)\n",
            "899 tensor(195.3937, grad_fn=<DivBackward0>)\n",
            "999 tensor(194.9044, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10001):\n",
        "  loss+= auto.train(train_loader)\n",
        "  if (i+1)%100==0:\n",
        "    print(i,loss/100)\n",
        "    loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mntg_PE0lqgp",
        "outputId": "1eb6ef98-0d58-4221-efb8-04f4e485b939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 tensor(196.0423, grad_fn=<DivBackward0>)\n",
            "199 tensor(192.1974, grad_fn=<DivBackward0>)\n",
            "299 tensor(193.3305, grad_fn=<DivBackward0>)\n",
            "399 tensor(191.1592, grad_fn=<DivBackward0>)\n",
            "499 tensor(189.6457, grad_fn=<DivBackward0>)\n",
            "599 tensor(187.7213, grad_fn=<DivBackward0>)\n",
            "699 tensor(185.5084, grad_fn=<DivBackward0>)\n",
            "799 tensor(185.7525, grad_fn=<DivBackward0>)\n",
            "899 tensor(184.2892, grad_fn=<DivBackward0>)\n",
            "999 tensor(183.2969, grad_fn=<DivBackward0>)\n",
            "1099 tensor(184.1989, grad_fn=<DivBackward0>)\n",
            "1199 tensor(182.4962, grad_fn=<DivBackward0>)\n",
            "1299 tensor(182.8329, grad_fn=<DivBackward0>)\n",
            "1399 tensor(181.5362, grad_fn=<DivBackward0>)\n",
            "1499 tensor(179.3150, grad_fn=<DivBackward0>)\n",
            "1599 tensor(180.2538, grad_fn=<DivBackward0>)\n",
            "1699 tensor(179.2937, grad_fn=<DivBackward0>)\n",
            "1799 tensor(179.5773, grad_fn=<DivBackward0>)\n",
            "1899 tensor(180.7877, grad_fn=<DivBackward0>)\n",
            "1999 tensor(178.5348, grad_fn=<DivBackward0>)\n",
            "2099 tensor(178.2026, grad_fn=<DivBackward0>)\n",
            "2199 tensor(177.6593, grad_fn=<DivBackward0>)\n",
            "2299 tensor(177.8409, grad_fn=<DivBackward0>)\n",
            "2399 tensor(177.4930, grad_fn=<DivBackward0>)\n",
            "2499 tensor(176.1320, grad_fn=<DivBackward0>)\n",
            "2599 tensor(176.0510, grad_fn=<DivBackward0>)\n",
            "2699 tensor(176.6268, grad_fn=<DivBackward0>)\n",
            "2799 tensor(175.7199, grad_fn=<DivBackward0>)\n",
            "2899 tensor(176.0771, grad_fn=<DivBackward0>)\n",
            "2999 tensor(176.6299, grad_fn=<DivBackward0>)\n",
            "3099 tensor(176.0908, grad_fn=<DivBackward0>)\n",
            "3199 tensor(174.4262, grad_fn=<DivBackward0>)\n",
            "3299 tensor(175.3992, grad_fn=<DivBackward0>)\n",
            "3399 tensor(174.0484, grad_fn=<DivBackward0>)\n",
            "3499 tensor(173.3097, grad_fn=<DivBackward0>)\n",
            "3599 tensor(173.3223, grad_fn=<DivBackward0>)\n",
            "3699 tensor(175.2871, grad_fn=<DivBackward0>)\n",
            "3799 tensor(174.5550, grad_fn=<DivBackward0>)\n",
            "3899 tensor(172.8746, grad_fn=<DivBackward0>)\n",
            "3999 tensor(173.7628, grad_fn=<DivBackward0>)\n",
            "4099 tensor(172.9811, grad_fn=<DivBackward0>)\n",
            "4199 tensor(172.0920, grad_fn=<DivBackward0>)\n",
            "4299 tensor(172.4031, grad_fn=<DivBackward0>)\n",
            "4399 tensor(172.0962, grad_fn=<DivBackward0>)\n",
            "4499 tensor(170.9919, grad_fn=<DivBackward0>)\n",
            "4599 tensor(170.7215, grad_fn=<DivBackward0>)\n",
            "4699 tensor(170.7389, grad_fn=<DivBackward0>)\n",
            "4799 tensor(171.9144, grad_fn=<DivBackward0>)\n",
            "4899 tensor(170.8197, grad_fn=<DivBackward0>)\n",
            "4999 tensor(171.1188, grad_fn=<DivBackward0>)\n",
            "5099 tensor(169.6739, grad_fn=<DivBackward0>)\n",
            "5199 tensor(170.0733, grad_fn=<DivBackward0>)\n",
            "5299 tensor(170.4983, grad_fn=<DivBackward0>)\n",
            "5399 tensor(170.8156, grad_fn=<DivBackward0>)\n",
            "5499 tensor(170.2916, grad_fn=<DivBackward0>)\n",
            "5599 tensor(169.8279, grad_fn=<DivBackward0>)\n",
            "5699 tensor(169.0795, grad_fn=<DivBackward0>)\n",
            "5799 tensor(170.9052, grad_fn=<DivBackward0>)\n",
            "5899 tensor(169.7829, grad_fn=<DivBackward0>)\n",
            "5999 tensor(169.6325, grad_fn=<DivBackward0>)\n",
            "6099 tensor(169.1005, grad_fn=<DivBackward0>)\n",
            "6199 tensor(169.4740, grad_fn=<DivBackward0>)\n",
            "6299 tensor(168.8883, grad_fn=<DivBackward0>)\n",
            "6399 tensor(169.3229, grad_fn=<DivBackward0>)\n",
            "6499 tensor(167.4608, grad_fn=<DivBackward0>)\n",
            "6599 tensor(167.3596, grad_fn=<DivBackward0>)\n",
            "6699 tensor(167.9804, grad_fn=<DivBackward0>)\n",
            "6799 tensor(168.3192, grad_fn=<DivBackward0>)\n",
            "6899 tensor(168.5206, grad_fn=<DivBackward0>)\n",
            "6999 tensor(172.3681, grad_fn=<DivBackward0>)\n",
            "7099 tensor(171.7407, grad_fn=<DivBackward0>)\n",
            "7199 tensor(170.1871, grad_fn=<DivBackward0>)\n",
            "7299 tensor(168.2765, grad_fn=<DivBackward0>)\n",
            "7399 tensor(168.4555, grad_fn=<DivBackward0>)\n",
            "7499 tensor(168.6719, grad_fn=<DivBackward0>)\n",
            "7599 tensor(169.6505, grad_fn=<DivBackward0>)\n",
            "7699 tensor(169.2230, grad_fn=<DivBackward0>)\n",
            "7799 tensor(169.1548, grad_fn=<DivBackward0>)\n",
            "7899 tensor(168.3650, grad_fn=<DivBackward0>)\n",
            "7999 tensor(168.1826, grad_fn=<DivBackward0>)\n",
            "8099 tensor(168.7398, grad_fn=<DivBackward0>)\n",
            "8199 tensor(169.1059, grad_fn=<DivBackward0>)\n",
            "8299 tensor(166.4697, grad_fn=<DivBackward0>)\n",
            "8399 tensor(167.2586, grad_fn=<DivBackward0>)\n",
            "8499 tensor(168.1566, grad_fn=<DivBackward0>)\n",
            "8599 tensor(167.3514, grad_fn=<DivBackward0>)\n",
            "8699 tensor(168.2692, grad_fn=<DivBackward0>)\n",
            "8799 tensor(168.5103, grad_fn=<DivBackward0>)\n",
            "8899 tensor(170.3184, grad_fn=<DivBackward0>)\n",
            "8999 tensor(168.5114, grad_fn=<DivBackward0>)\n",
            "9099 tensor(167.7075, grad_fn=<DivBackward0>)\n",
            "9199 tensor(167.1742, grad_fn=<DivBackward0>)\n",
            "9299 tensor(166.3521, grad_fn=<DivBackward0>)\n",
            "9399 tensor(167.8094, grad_fn=<DivBackward0>)\n",
            "9499 tensor(167.3663, grad_fn=<DivBackward0>)\n",
            "9599 tensor(166.7327, grad_fn=<DivBackward0>)\n",
            "9699 tensor(165.9437, grad_fn=<DivBackward0>)\n",
            "9799 tensor(166.1604, grad_fn=<DivBackward0>)\n",
            "9899 tensor(166.4907, grad_fn=<DivBackward0>)\n",
            "9999 tensor(165.7255, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 901\n",
        "\n",
        "\n",
        "f, axarr = plt.subplots(1,2)\n",
        "\n",
        "# genr = auto.decoder(auto.encoder(dataset2[i][0].to(device)))\n",
        "# img = dataset2[i][0]\n",
        "# bin_img = (img>0.5).float()\n",
        "\n",
        "# plt.imshow(bin_img.detach().cpu().squeeze(),cmap='gray')\n",
        "standard_nor = torch.distributions.MultivariateNormal(torch.zeros(10,), torch.eye(10,))\n",
        "\n",
        "latent = standard_nor.sample()\n",
        "\n",
        "bern = auto.decoder(latent)\n",
        "\n",
        "ber_dist = Bernoulli(bern)\n",
        "\n",
        "\n",
        "generated_smooth = bern.reshape(-1,1,28,28)\n",
        "generated_sample = ber_dist.sample().reshape(-1,1,28,28)\n",
        "# plt.imshow(generated.detach().cpu().squeeze(),cmap='gray')\n",
        "\n",
        "\n",
        "axarr[0].imshow(generated_smooth.detach().cpu().squeeze(),cmap='gray')\n",
        "axarr[1].imshow(generated_sample.detach().cpu().squeeze(),cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "n-MGiU-okF5L",
        "outputId": "2fc5c303-b683-48f1-ffa5-409d5d57aca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f97f87baf50>"
            ]
          },
          "metadata": {},
          "execution_count": 207
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}